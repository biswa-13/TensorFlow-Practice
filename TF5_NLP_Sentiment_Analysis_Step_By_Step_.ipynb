{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF5 NLP - Sentiment Analysis Step By Step .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPERsSiYcF0NuR1QM21qjtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biswa-13/TensorFlow-Practice/blob/master/TF5_NLP_Sentiment_Analysis_Step_By_Step_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GTVzVninAUl",
        "colab_type": "text"
      },
      "source": [
        "**Step By Step Guid for Doing the Sentiment Analysis using Tensoflow :**\n",
        "- Import the required packages and declaire the variables\n",
        "- Download the dataset\n",
        "- Prepare the training and testing dataset\n",
        "- Tokenizing, Sequencing and Padding the dataset\n",
        "- Create the model\n",
        "- Train the model using the keras Embeddings layer\n",
        "- Predict/Test the model accuracy\n",
        "\n",
        "Reference : https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c04_nlp_embeddings_and_sentiment.ipynb#scrollTo=QXtfw-OY3WoZ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e94GP_6zzPZg",
        "colab_type": "code",
        "outputId": "57181f1a-6722-4b00-8b33-6ff8c8d7c734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#- Import the required packages and declaire the variables\n",
        "print(\"Start - Import the required packages and declaire the variables\")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "vocab_size = 1000\n",
        "embeding_dimensions = 16\n",
        "max_len = 50\n",
        "oov_token = \"<OOv>\"\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "\n",
        "print(\"Finish - Import the required packages and declaire the variables\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start - Import the required packages and declaire the variables\n",
            "Finish - Import the required packages and declaire the variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B12UFpv_V5l-",
        "colab_type": "code",
        "outputId": "c07d145a-03dd-4851-df6a-9f7541998bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# - Downloading the Dataset\n",
        "print(\"Start: Downloading the Dataset -->\")\n",
        "path = tf.keras.utils.get_file(\"reviewDataset.csv\", \"https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\")\n",
        "\n",
        "# Retriving the downloaded datasset\n",
        "dataset = pd.read_csv(path)\n",
        "dataset.head()\n",
        "print(\"Finish: Downloading the Dataset -->\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Downloading the Dataset -->\n",
            "Finish: Downloading the Dataset -->\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSVHLW_5Wh4c",
        "colab_type": "code",
        "outputId": "9115f04d-8ad8-4e5b-9cfd-f3f71f11059b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#- Prepare the training and testing dataset\n",
        "\n",
        "print(\"Start - Prepare the training and testing dataset\")\n",
        "# Get the reviews and lables from the csv file\n",
        "reviews = dataset[\"text\"]\n",
        "labels = dataset[\"sentiment\"]\n",
        "train_size = int(len(reviews) * 0.8)\n",
        "\n",
        "train_dataset = reviews[0: train_size]\n",
        "train_labels = labels[0:train_size]\n",
        "\n",
        "test_dataset = reviews[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "# Make labels into numpy arrays for use with the network later\n",
        "updtd_train_lbls = np.array(train_labels)\n",
        "updtd_test_lbls = np.array(test_labels)\n",
        "print(\"Finish - Prepare the training and testing dataset\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start - Prepare the training and testing dataset\n",
            "Finish - Prepare the training and testing dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGw8xIrLp4zb",
        "colab_type": "code",
        "outputId": "159e7182-a0cc-46b5-a624-e3ce67bd4a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# - Tokenize the dataset\n",
        "print(\"Start - Tokenizing, Sequencing and Padding the dataset\")\n",
        "# -- initializing the tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "# -- tokenizing the words\n",
        "tokenizer.fit_on_texts(train_dataset)\n",
        "# -- retriving the wordIndex\n",
        "wordIndex = tokenizer.word_index\n",
        "# -- generating the text sequences\n",
        "sequences_train = tokenizer.texts_to_sequences(train_dataset)\n",
        "# -- applying the paading configurations\n",
        "padding_train = pad_sequences(sequences= sequences_train, maxlen= max_len, padding= padding_type, truncating= trunc_type)\n",
        "\n",
        "# generating sequence and padding for the test dataset\n",
        "sequence_test = tokenizer.texts_to_sequences(test_dataset)\n",
        "padding_test = pad_sequences(sequences= sequence_test, maxlen = max_len, padding= padding_type, truncating= trunc_type)\n",
        "print(\"Finish - Tokenizing, Sequencing and Padding the dataset\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start - Tokenizing, Sequencing and Padding the dataset\n",
            "Finish - Tokenizing, Sequencing and Padding the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UsxbSKKvBOn",
        "colab_type": "code",
        "outputId": "dbcafef3-8af3-4164-d512-addc3fa8e81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# - Building the model using the keras Embeddings layer\n",
        "print(\"Start - Building the model using the keras Embeddings layer\")\n",
        "\n",
        "# Build a basic sentiment network\n",
        "# Note the embedding layer is first, \n",
        "# and the output is only 1 node as it is either 0 or 1 (negative or positive)\n",
        "\n",
        "## initializing the model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, embeding_dimensions, input_length=max_len),\n",
        "                             #tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(6, activation= \"relu\"),\n",
        "                             tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "## compiling the model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer= 'adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "print(\"Finish - Building the model using the keras Embeddings layer\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start - Building the model using the keras Embeddings layer\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 16)            16000     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 102       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 16,109\n",
            "Trainable params: 16,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Finish - Building the model using the keras Embeddings layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgdA0dXtzFiT",
        "colab_type": "code",
        "outputId": "d614307c-54c7-44fc-9092-77887f3041b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# - Training the model\n",
        "print(\"Start - Training the model\")\n",
        "epochs = 35\n",
        "history = model.fit(padding_train, updtd_train_lbls, epochs= epochs, validation_data= (padding_test, updtd_test_lbls))\n",
        "history\n",
        "print(\"Finish - Training the model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start - Training the model\n",
            "Epoch 1/35\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5223 - val_loss: 0.6973 - val_accuracy: 0.4110\n",
            "Epoch 2/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5267 - val_loss: 0.6954 - val_accuracy: 0.4261\n",
            "Epoch 3/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5455 - val_loss: 0.6945 - val_accuracy: 0.4386\n",
            "Epoch 4/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6095 - val_loss: 0.6890 - val_accuracy: 0.4862\n",
            "Epoch 5/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6460 - val_loss: 0.6676 - val_accuracy: 0.6767\n",
            "Epoch 6/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7414 - val_loss: 0.6539 - val_accuracy: 0.6692\n",
            "Epoch 7/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.7721 - val_loss: 0.6280 - val_accuracy: 0.7719\n",
            "Epoch 8/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.8104 - val_loss: 0.6083 - val_accuracy: 0.7594\n",
            "Epoch 9/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.8355 - val_loss: 0.5828 - val_accuracy: 0.7820\n",
            "Epoch 10/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8468 - val_loss: 0.5624 - val_accuracy: 0.7820\n",
            "Epoch 11/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8481 - val_loss: 0.5352 - val_accuracy: 0.7845\n",
            "Epoch 12/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8757 - val_loss: 0.5408 - val_accuracy: 0.7619\n",
            "Epoch 13/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8851 - val_loss: 0.5074 - val_accuracy: 0.7995\n",
            "Epoch 14/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8914 - val_loss: 0.5040 - val_accuracy: 0.7945\n",
            "Epoch 15/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8952 - val_loss: 0.5050 - val_accuracy: 0.7870\n",
            "Epoch 16/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.9033 - val_loss: 0.4712 - val_accuracy: 0.7995\n",
            "Epoch 17/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.9077 - val_loss: 0.4774 - val_accuracy: 0.7970\n",
            "Epoch 18/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.9146 - val_loss: 0.4672 - val_accuracy: 0.8020\n",
            "Epoch 19/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.9134 - val_loss: 0.4771 - val_accuracy: 0.7820\n",
            "Epoch 20/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9234 - val_loss: 0.4544 - val_accuracy: 0.7995\n",
            "Epoch 21/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9316 - val_loss: 0.4822 - val_accuracy: 0.7719\n",
            "Epoch 22/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9353 - val_loss: 0.4481 - val_accuracy: 0.8095\n",
            "Epoch 23/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9385 - val_loss: 0.5088 - val_accuracy: 0.7544\n",
            "Epoch 24/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9372 - val_loss: 0.4676 - val_accuracy: 0.7870\n",
            "Epoch 25/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9441 - val_loss: 0.4710 - val_accuracy: 0.7870\n",
            "Epoch 26/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9448 - val_loss: 0.4531 - val_accuracy: 0.7970\n",
            "Epoch 27/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9485 - val_loss: 0.4552 - val_accuracy: 0.7920\n",
            "Epoch 28/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9554 - val_loss: 0.4691 - val_accuracy: 0.7870\n",
            "Epoch 29/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9504 - val_loss: 0.4837 - val_accuracy: 0.7845\n",
            "Epoch 30/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9554 - val_loss: 0.4704 - val_accuracy: 0.7820\n",
            "Epoch 31/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9579 - val_loss: 0.4674 - val_accuracy: 0.7845\n",
            "Epoch 32/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9630 - val_loss: 0.4868 - val_accuracy: 0.7845\n",
            "Epoch 33/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9630 - val_loss: 0.5041 - val_accuracy: 0.7870\n",
            "Epoch 34/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9642 - val_loss: 0.4988 - val_accuracy: 0.7845\n",
            "Epoch 35/35\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9648 - val_loss: 0.5063 - val_accuracy: 0.7820\n",
            "Finish - Training the model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9m4MFf22vGn",
        "colab_type": "code",
        "outputId": "83819eee-9acf-40b5-c23e-404de3d976b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "# - Testing the model\n",
        "print(\"Start: Testing the model\")\n",
        "# Use the model to predict a review   \n",
        "fake_reviews = ['I love this phone', 'I hate spaghetti', \n",
        "                'Everything was cold',\n",
        "                'Everything was hot exactly as I wanted', \n",
        "                'Everything was green that is good but i dont like the green', \n",
        "                'the host seated us immediately',\n",
        "                'they gave us free chocolate cake', \n",
        "                'not sure about the wilted flowers on the table',\n",
        "                'only works when I stand on tippy toes', \n",
        "                'does not work when I stand on my head']\n",
        "\n",
        "print(fake_reviews) \n",
        "\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_len)           \n",
        "\n",
        "print('\\nHOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\\n')              \n",
        "\n",
        "classes = model.predict(fakes_padded)\n",
        "\n",
        "# The closer the class is to 1, the more positive the review is deemed to be\n",
        "for x in range(len(fake_reviews)):\n",
        "  print(fake_reviews[x])\n",
        "  print(classes[x])\n",
        "  print('\\n')\n",
        "\n",
        "# Try adding reviews of your own\n",
        "# Add some negative words (such as \"not\") to the good reviews and see what happens\n",
        "# For example:\n",
        "# they gave us free chocolate cake and did not charge us\n",
        "print(\"Start: Testing the model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Testing the model\n",
            "['I love this phone', 'I hate spaghetti', 'Everything was cold', 'Everything was hot exactly as I wanted', 'Everything was green that is good but i dont like the green', 'the host seated us immediately', 'they gave us free chocolate cake', 'not sure about the wilted flowers on the table', 'only works when I stand on tippy toes', 'does not work when I stand on my head']\n",
            "\n",
            "HOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\n",
            "\n",
            "I love this phone\n",
            "[0.9701623]\n",
            "\n",
            "\n",
            "I hate spaghetti\n",
            "[0.08358482]\n",
            "\n",
            "\n",
            "Everything was cold\n",
            "[0.27471662]\n",
            "\n",
            "\n",
            "Everything was hot exactly as I wanted\n",
            "[0.7794906]\n",
            "\n",
            "\n",
            "Everything was green that is good but i dont like the green\n",
            "[0.9083581]\n",
            "\n",
            "\n",
            "the host seated us immediately\n",
            "[0.90352964]\n",
            "\n",
            "\n",
            "they gave us free chocolate cake\n",
            "[0.91834384]\n",
            "\n",
            "\n",
            "not sure about the wilted flowers on the table\n",
            "[0.03863707]\n",
            "\n",
            "\n",
            "only works when I stand on tippy toes\n",
            "[0.9582824]\n",
            "\n",
            "\n",
            "does not work when I stand on my head\n",
            "[0.01534714]\n",
            "\n",
            "\n",
            "Start: Testing the model\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}