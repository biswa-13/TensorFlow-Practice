{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn Tensorflow 2.1: Introduction to Computer Vision with CallBack.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk9fWNfTt4dL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "a7d2e031-1659-4231-b3ca-43d1f3c5fc8a"
      },
      "source": [
        "# importing the packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# fetching required dataset\n",
        "fmnist = keras.datasets.fashion_mnist\n",
        "\n",
        "# creating training and testing datasets\n",
        "(training_img, training_labels), (testing_img, testing_labels) = fmnist.load_data()\n",
        "\n",
        "# normalizing the training datasets\n",
        "training_img = training_img/255.0\n",
        "training_labels = training_labels/255.0\n",
        "\n",
        "# initializing the model\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "     tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ]\n",
        "    \n",
        ")\n",
        "\n",
        "# compling the model\n",
        "model.compile(\n",
        "    optimizer = tf.train.AdamOptimizer(),\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# callback function to watch the training process and stop it after a particular accuracy(ex : 95%)\n",
        "\n",
        "class accuracyCallBack(tf.keras.callbacks.Callback):\n",
        "  def on_accuracy_achived(self, epoch, logs={}):\n",
        "    if(logs.get('acc') > 0.95):\n",
        "      print(\"Accuracy of > 95 is achived, so going to stop the training process...\")\n",
        "      self.model.stop_training= True\n",
        "    else:\n",
        "      print(\"Accuracy is not satisfied !!!\")\n",
        "\n",
        "callback = accuracyCallBack()\n",
        "# training the model\n",
        "model.fit(\n",
        "    training_img,\n",
        "    training_labels, \n",
        "    epochs=15,\n",
        "    callbacks = [callback]\n",
        ")\n",
        "\n",
        "# evaluate the accuracy\n",
        "model.evaluate(testing_img, testing_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0025 - acc: 0.1000\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 5.5570e-07 - acc: 0.1000\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 1.4088e-07 - acc: 0.1000\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 4.8778e-08 - acc: 0.1000\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 1.9019e-08 - acc: 0.1000\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 7.3820e-09 - acc: 0.1000\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 3.0953e-09 - acc: 0.1000\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 1.2318e-09 - acc: 0.1000\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 4.3511e-10 - acc: 0.1000\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 2.4040e-10 - acc: 0.1000\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 1.2120e-10 - acc: 0.1000\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 6.3578e-11 - acc: 0.1000\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 3.9736e-11 - acc: 0.1000\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 2.1855e-11 - acc: 0.1000\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 1.3908e-11 - acc: 0.1000\n",
            "10000/10000 [==============================] - 0s 38us/sample - loss: 31128.0933 - acc: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31128.09331875, 0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLySVI3hYTOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "52c26696-74ec-4689-a3fe-9d2bff8cdafe"
      },
      "source": [
        "# testing the model\n",
        "clasification = model.predict(testing_img)\n",
        "print(clasification[8])\n",
        "print(testing_labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}